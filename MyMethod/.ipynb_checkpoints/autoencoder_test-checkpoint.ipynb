{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "# this code is used to check whether my gradient calculation can be used\n",
    "import os\n",
    "import sys\n",
    "BASE_DIR = os.getcwd()\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# print('current working dirctory = ',BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "output_size = 28*28\n",
    "LOG_DIR = BASE_DIR + '/log'\n",
    "# 设定了一个log 的路径，方便如何存入和读取模型\n",
    "if not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autoencoder_outputs(autoencoder, n, dims):\n",
    "    decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "    # number of example digits to show\n",
    "    n = 5\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    for i in range(n):\n",
    "        # plot original image\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Original Images')\n",
    "\n",
    "        # plot reconstruction \n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Reconstructed Images')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, historydf.values.max()))\n",
    "    plt.title('Loss: %.3f' % history.history['loss'][-1])\n",
    "    \n",
    "def plot_compare_histories(history_list, name_list, plot_accuracy=True):\n",
    "    dflist = []\n",
    "    min_epoch = len(history_list[0].epoch)\n",
    "    losses = []\n",
    "    for history in history_list:\n",
    "        h = {key: val for key, val in history.history.items() if not key.startswith('val_')}\n",
    "        dflist.append(pd.DataFrame(h, index=history.epoch))\n",
    "        min_epoch = min(min_epoch, len(history.epoch))\n",
    "        losses.append(h['loss'][-1])\n",
    "\n",
    "    historydf = pd.concat(dflist, axis=1)\n",
    "\n",
    "    metrics = dflist[0].columns\n",
    "    idx = pd.MultiIndex.from_product([name_list, metrics], names=['model', 'metric'])\n",
    "    historydf.columns = idx\n",
    "    \n",
    "    plt.figure(figsize=(6, 8))\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    historydf.xs('loss', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "    plt.title(\"Training Loss: \" + ' vs '.join([str(round(x, 3)) for x in losses]))\n",
    "    \n",
    "    if plot_accuracy:\n",
    "        ax = plt.subplot(212)\n",
    "        historydf.xs('acc', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "    \n",
    "    plt.xlim(0, min_epoch-1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff74e8108d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = x_test[0].reshape((28,28))\n",
    "test_image = (test_image * 255).astype('uint8')\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "# 传统的定义方法\n",
    "def autoencode(x):\n",
    "    #l1 = tf.nn.tanh(fc_layer(x, 28*28, 50))\n",
    "    #l2 = tf.nn.tanh(fc_layer(l1, 50, 50))\n",
    "    #l3 = fc_layer(l2, 50, 2)\n",
    "    #l4 = tf.nn.tanh(fc_layer(l3, 2, 50))\n",
    "    #l5 = tf.nn.tanh(fc_layer(l4, 50, 50))\n",
    "    l1 = Dense(128,activation = tf.nn.relu)(x)\n",
    "    l2 = Dense(128,activation = tf.nn.relu)(l1)\n",
    "    l3 = Dense(32)(l2)\n",
    "    l4 = Dense(128,activation = tf.nn.relu)(l3)\n",
    "    l5 = Dense(128,activation = tf.nn.relu)(l4)\n",
    "    out = Dense(input_size,activation = 'sigmoid')(l5)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.squared_difference(x, out))\n",
    "    return loss, out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difine two placeholder。This is the old fashion tensorflow method\n",
    "# 训练自编码，传统方式在使用一天之后终于奏效了\n",
    "x_pl = tf.placeholder(tf.float32,shape = [None,input_size],name = 'x_pl')\n",
    "print(x_pl.shape)\n",
    "batchsize = 20\n",
    "range_val = int(60000/batchsize)\n",
    "loss,output = autoencode(x_pl)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        if(epoch % 1 == 0):\n",
    "            print('this is the ',epoch,' epoch')\n",
    "        for i in range(range_val):\n",
    "            batch_index = i\n",
    "            train_i = x_train[batchsize * batch_index:batchsize * (batch_index + 1),:]\n",
    "            feed = {x_pl:train_i} \n",
    "            my_loss ,_ = sess.run([loss,train_op],feed_dict =feed)\n",
    "    # save the model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess,os.path.join(LOG_DIR,'autoencoder2.ckpt'))\n",
    "    # check the output of the result\n",
    "    test_img = x_test[0].reshape((1,784))\n",
    "    networkoutput = sess.run(output,feed_dict = {x_pl:test_img})\n",
    "    print(networkoutput.shape)\n",
    "    output_img = networkoutput.reshape((28,28))\n",
    "    output_img = (output_img * 255).astype('uint8')\n",
    "    plt.imshow(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 102       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 784)               39984     \n",
      "=================================================================\n",
      "Total params: 84,586\n",
      "Trainable params: 84,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(50,input_shape = (input_size,),activation = 'tanh'))\n",
    "model.add(Dense(50,activation = 'tanh'))\n",
    "model.add(Dense(2))\n",
    "model.add(Dense(50,activation = 'tanh'))\n",
    "model.add(Dense(50,activation = 'tanh'))\n",
    "model.add(Dense(input_size))\n",
    "model.summary()\n",
    "def cusloss(ytrue,ypred):\n",
    "    loss = tf.reduce_sum(tf.squared_difference(ypred,ytrue))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 1376.8814\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 1180.3271\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 1112.9563\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 1081.5507\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 1062.5646\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 1049.1525\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 1036.9017\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 1026.8213\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 1019.1869\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 1009.8974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff7103e06d8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = cusloss,\n",
    "              optimizer = 'adam')\n",
    "model.fit(x_train,x_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x324 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_autoencoder_outputs(model, 5, (28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "x_train = np.reshape(x_train,[60000,28,28,1])\n",
    "x_test = np.reshape(x_test,[10000,28,28,1])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传统的定义方法\n",
    "def digitNet(x,label):\n",
    "    conv1 = Conv2D(32,(5,5),activation = 'relu')(x)\n",
    "    MP1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    Dp1 =Dropout(rate = 0.2)(MP1)\n",
    "    Flat = Flatten()(Dp1)\n",
    "    fc1 = Dense(128,activation = 'relu')(Flat)\n",
    "    out = Dense(10,activation = 'softmax')(fc1)\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=out, labels=label)\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n",
      "(?,)\n",
      "this is the  0  epoch\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_4/Conv2D (defined at <ipython-input-23-f8b431c15015>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-23-f8b431c15015>:10) ]]\n\nCaused by op 'conv2d_4/Conv2D', defined at:\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-e6b6a084a8d6>\", line 11, in <module>\n    loss,output = digitNet(x_pl,label_pl)\n  File \"<ipython-input-23-f8b431c15015>\", line 3, in digitNet\n    conv1 = Conv2D(32,(5,5),activation = 'relu')(x)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_4/Conv2D (defined at <ipython-input-23-f8b431c15015>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-23-f8b431c15015>:10) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_4/Conv2D}}]]\n\t [[{{node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e6b6a084a8d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mlabel_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx_pl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_pl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel_i\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mmy_loss\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_4/Conv2D (defined at <ipython-input-23-f8b431c15015>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-23-f8b431c15015>:10) ]]\n\nCaused by op 'conv2d_4/Conv2D', defined at:\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-e6b6a084a8d6>\", line 11, in <module>\n    loss,output = digitNet(x_pl,label_pl)\n  File \"<ipython-input-23-f8b431c15015>\", line 3, in digitNet\n    conv1 = Conv2D(32,(5,5),activation = 'relu')(x)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_4/Conv2D (defined at <ipython-input-23-f8b431c15015>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-23-f8b431c15015>:10) ]]\n"
     ]
    }
   ],
   "source": [
    "# difine two placeholder。This is the old fashion tensorflow method\n",
    "# 训练数字识别器，loss function选择了和POINTNER++一样的方式去构建 \n",
    "x_pl = tf.placeholder(tf.float32,shape = [None,28,28,1],name = 'x_pl')\n",
    "label_pl = tf.placeholder(tf.int32,shape = [None],name = 'label_pl')\n",
    "print(x_pl.shape)\n",
    "print(label_pl.shape)\n",
    "\n",
    "batchsize = 20\n",
    "range_val = int(60000/batchsize)\n",
    "\n",
    "loss,output = digitNet(x_pl,label_pl)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        if(epoch % 1 == 0):\n",
    "            print('this is the ',epoch,' epoch')\n",
    "        for i in range(range_val):\n",
    "            batch_index = i\n",
    "            train_i = x_train[batchsize * batch_index:batchsize * (batch_index + 1),:]\n",
    "            label_i = y_train[batchsize * batch_index:batchsize * (batch_index + 1)]\n",
    "            feed = {x_pl:train_i,label_pl:label_i} \n",
    "            my_loss ,_ = sess.run([loss,train_op],feed_dict =feed)\n",
    "            \n",
    "    # save the model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess,os.path.join(LOG_DIR,'digitNet.ckpt'))\n",
    "    # check the output of the result\n",
    "    test_img = x_test[0].reshape(1,28,28,1)\n",
    "    networkoutput = sess.run(output,feed_dict = {x_pl:test_img})\n",
    "    prediction = np.argmax(networkoutput)\n",
    "    print('networkoutput',networkoutput.shape)\n",
    "    print('prediction = ',prediction,prediction.shape)\n",
    "    print('label = ',y_test[0])\n",
    "    #output_img = networkoutput.reshape((28,28))\n",
    "    #output_img = (output_img * 255).astype('uint8')\n",
    "    #plt.imshow(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_img (1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#print('networkoutput = ',networkoutput)\n",
    "test_img = x_test[0].reshape(1,28,28,1)\n",
    "print('test_img',test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上面图过后成功完成训练了，接下来就是保存模型并提取模型，然后用自编码模型完成老师的任务了\n",
    "# restore the model\n",
    "MODEL_PATH = os.path.join(LOG_DIR,'digitNet.ckpt')\n",
    "# 要先把网络结构重新引进回来之后才能使用saver\n",
    "x_pl = tf.placeholder(tf.float32,shape = [None,28,28,1],name = 'x_pl')\n",
    "label_pl = tf.placeholder(tf.int32,shape = [None],name = 'label_pl')\n",
    "_,output = digitNet(x_pl,label_pl)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 这个方法需要每一个tensor的名字来使用，还不如重新声明一次网络来的实在\n",
    "    # saver = tf.train.import_meta_graph(LOG_DIR + '/digitNet.ckpt.meta')\n",
    "    graph = tf.get_default_graph()    \n",
    "    saver.restore(sess, MODEL_PATH)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "    networkoutput = sess.run(output,feed_dict = {x_pl:test_img})\n",
    "    \n",
    "    prediction = np.argmax(networkoutput)\n",
    "    print('networkoutput',networkoutput.shape)\n",
    "    print('prediction = ',prediction,prediction.shape)\n",
    "    print('label = ',y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
