{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "# this code is used to check whether my gradient calculation can be used\n",
    "import os\n",
    "import sys\n",
    "BASE_DIR = os.getcwd()\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# print('current working dirctory = ',BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "output_size = 28*28\n",
    "LOG_DIR = BASE_DIR + '/log'\n",
    "# 设定了一个log 的路径，方便如何存入和读取模型\n",
    "if not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autoencoder_outputs(autoencoder, n, dims):\n",
    "    decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "    # number of example digits to show\n",
    "    n = 5\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    for i in range(n):\n",
    "        # plot original image\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Original Images')\n",
    "\n",
    "        # plot reconstruction \n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Reconstructed Images')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, historydf.values.max()))\n",
    "    plt.title('Loss: %.3f' % history.history['loss'][-1])\n",
    "    \n",
    "def plot_compare_histories(history_list, name_list, plot_accuracy=True):\n",
    "    dflist = []\n",
    "    min_epoch = len(history_list[0].epoch)\n",
    "    losses = []\n",
    "    for history in history_list:\n",
    "        h = {key: val for key, val in history.history.items() if not key.startswith('val_')}\n",
    "        dflist.append(pd.DataFrame(h, index=history.epoch))\n",
    "        min_epoch = min(min_epoch, len(history.epoch))\n",
    "        losses.append(h['loss'][-1])\n",
    "\n",
    "    historydf = pd.concat(dflist, axis=1)\n",
    "\n",
    "    metrics = dflist[0].columns\n",
    "    idx = pd.MultiIndex.from_product([name_list, metrics], names=['model', 'metric'])\n",
    "    historydf.columns = idx\n",
    "    \n",
    "    plt.figure(figsize=(6, 8))\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    historydf.xs('loss', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "    plt.title(\"Training Loss: \" + ' vs '.join([str(round(x, 3)) for x in losses]))\n",
    "    \n",
    "    if plot_accuracy:\n",
    "        ax = plt.subplot(212)\n",
    "        historydf.xs('acc', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "    \n",
    "    plt.xlim(0, min_epoch-1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa464519f60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAANh0lEQVR4nO3df6zddX3H8dfL/sJeYFKwtSuVKqKxOsHlCppuSw3DAYYUo2w0GekSZskGCSxmG2ExkmxxjIiETWdSR2clCFOBQLRzksaNkLHKhZRSKFuRdVh71wvUrUXgtqXv/XG/LJdyz+dezvd7zve07+cjuTnnfN/ne77vfHtf/X7v+XzP+TgiBODY95a2GwDQH4QdSIKwA0kQdiAJwg4kMbufG5vreXGchvq5SSCVV/QLHYhxT1WrFXbb50u6RdIsSX8XETeUnn+chnSOz62zSQAFm2NTx1rXp/G2Z0n6qqQLJC2XtNr28m5fD0Bv1fmb/WxJT0fEMxFxQNKdklY10xaAptUJ+xJJP530eFe17HVsr7U9YnvkoMZrbA5AHXXCPtWbAG+49jYi1kXEcEQMz9G8GpsDUEedsO+StHTS41Ml7a7XDoBeqRP2hyWdYftdtudKulTSfc20BaBpXQ+9RcQh21dJ+idNDL2tj4gnGusMQKNqjbNHxEZJGxvqBUAPcbkskARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlaUzbb3ilpv6RXJR2KiOEmmgLQvFphr3w8Ip5v4HUA9BCn8UASdcMekn5o+xHba6d6gu21tkdsjxzUeM3NAehW3dP4FRGx2/ZCSffbfioiHpj8hIhYJ2mdJJ3oBVFzewC6VOvIHhG7q9sxSfdIOruJpgA0r+uw2x6yfcJr9yV9QtK2phoD0Kw6p/GLJN1j+7XX+VZE/KCRrgA0ruuwR8Qzks5ssBcAPcTQG5AEYQeSIOxAEoQdSIKwA0k08UGYFF747Mc61t552dPFdZ8aW1SsHxifU6wvuaNcn7/rxY61w1ueLK6LPDiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLPP0J/88bc61j499PPyyqfX3PjKcnnnoZc61m557uM1N370+vHYaR1rQzf9UnHd2Zseabqd1nFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHNG/SVpO9II4x+f2bXtN+sVnzulYe/5D5f8zT9pe3sc/f7+L9bkf+p9i/cYP3t2xdt5bXy6u+/2Xji/WPzm/82fl63o5DhTrm8eHivWVxx3setvv+f4Vxfp71z7c9Wu3aXNs0r7YO+UvFEd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCz7PP0NB3Nxdq9V77xHqr62/esbJj7S9WLCtv+1/K33l/48r3dNHRzMx++XCxPrR1tFg/+YG7ivVfmdv5+/bn7yx/F/+xaNoju+31tsdsb5u0bIHt+23vqG5P6m2bAOqayWn8NySdf8SyayVtiogzJG2qHgMYYNOGPSIekLT3iMWrJG2o7m+QdHHDfQFoWLdv0C2KiFFJqm4Xdnqi7bW2R2yPHNR4l5sDUFfP342PiHURMRwRw3M0r9ebA9BBt2HfY3uxJFW3Y821BKAXug37fZLWVPfXSLq3mXYA9Mq04+y279DEN5efYnuXpC9IukHSt21fLulZSZf0skmUHfrvPR1rQ3d1rknSq9O89tB3X+iio2bs+f2PFesfmFv+9f3S3vd1rC37+2eK6x4qVo9O04Y9IlZ3KB2d30IBJMXlskAShB1IgrADSRB2IAnCDiTBR1zRmtmnLS3Wv3LdV4r1OZ5VrH/nlt/sWDt59KHiuscijuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7GjNU3+0pFj/yLzyVNZPHChPR73gyZfedE/HMo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zoqfFPfqRj7dHP3DzN2uUZhP7g6quL9bf+64+nef1cOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6Onnr2g8/HkeJfH0Vf/53nF+vwfPFasR7Gaz7RHdtvrbY/Z3jZp2fW2f2Z7S/VzYW/bBFDXTE7jvyHp/CmW3xwRZ1U/G5ttC0DTpg17RDwgaW8fegHQQ3XeoLvK9tbqNP+kTk+yvdb2iO2RgxqvsTkAdXQb9q9JOl3SWZJGJd3U6YkRsS4ihiNieM40H2wA0DtdhT0i9kTEqxFxWNLXJZ3dbFsAmtZV2G0vnvTwU5K2dXougMEw7Ti77TskrZR0iu1dkr4gaaXtszQxlLlT0hU97BED7C0nnFCsX/brD3as7Tv8SnHdsS++u1ifN/5wsY7XmzbsEbF6isW39qAXAD3E5bJAEoQdSIKwA0kQdiAJwg4kwUdcUcuO6z9QrH/vlL/tWFu149PFdedtZGitSRzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlR9L+/+9Fifevv/HWx/pNDBzvWXvyrU4vrztNosY43hyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtys5f8crF+zef/oVif5/Kv0KWPXdax9vZ/5PPq/cSRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJz9GOfZ5X/iM7+3q1i/5PgXivXb9y8s1hd9vvPx5HBxTTRt2iO77aW2f2R7u+0nbF9dLV9g+37bO6rbk3rfLoBuzeQ0/pCkz0XE+yV9VNKVtpdLulbSpog4Q9Km6jGAATVt2CNiNCIere7vl7Rd0hJJqyRtqJ62QdLFvWoSQH1v6g0628skfVjSZkmLImJUmvgPQdKUf7zZXmt7xPbIQY3X6xZA12YcdtvHS7pL0jURsW+m60XEuogYjojhOZrXTY8AGjCjsNueo4mg3x4Rd1eL99heXNUXSxrrTYsAmjDt0JttS7pV0vaI+PKk0n2S1ki6obq9tycdop4z31cs//nC22q9/Fe/eEmx/rbHHqr1+mjOTMbZV0i6TNLjtrdUy67TRMi/bftySc9KKv+rA2jVtGGPiAcluUP53GbbAdArXC4LJEHYgSQIO5AEYQeSIOxAEnzE9Rgwa/l7O9bW3lnv8ofl668s1pfd9m+1Xh/9w5EdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnP0Y8NQfdv5i34vmz/hLhaZ06j8fKD8hotbro384sgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzHwVeuejsYn3TRTcVqvObbQZHLY7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5DETOZnXyrpm5LeIemwpHURcYvt6yV9VtJz1VOvi4iNvWo0s90rZhXr75zd/Vj67fsXFutz9pU/z86n2Y8eM7mo5pCkz0XEo7ZPkPSI7fur2s0R8aXetQegKTOZn31U0mh1f7/t7ZKW9LoxAM16U3+z214m6cOSNleLrrK91fZ621N+N5LttbZHbI8c1HitZgF0b8Zht328pLskXRMR+yR9TdLpks7SxJF/ygu0I2JdRAxHxPAczWugZQDdmFHYbc/RRNBvj4i7JSki9kTEqxFxWNLXJZU/rQGgVdOG3bYl3Sppe0R8edLyxZOe9ilJ25pvD0BTZvJu/ApJl0l63PaWatl1klbbPksToy87JV3Rkw5Ry1++sLxYf+i3lhXrMfp4g92gTTN5N/5BSZ6ixJg6cBThCjogCcIOJEHYgSQIO5AEYQeSIOxAEo4+Trl7ohfEOT63b9sDstkcm7Qv9k41VM6RHciCsANJEHYgCcIOJEHYgSQIO5AEYQeS6Os4u+3nJP3XpEWnSHq+bw28OYPa26D2JdFbt5rs7bSIePtUhb6G/Q0bt0ciYri1BgoGtbdB7Uuit271qzdO44EkCDuQRNthX9fy9ksGtbdB7Uuit271pbdW/2YH0D9tH9kB9AlhB5JoJey2z7f977aftn1tGz10Ynun7cdtb7E90nIv622P2d42adkC2/fb3lHdTjnHXku9XW/7Z9W+22L7wpZ6W2r7R7a3237C9tXV8lb3XaGvvuy3vv/NbnuWpP+QdJ6kXZIelrQ6Ip7sayMd2N4paTgiWr8Aw/ZvSHpR0jcj4oPVshsl7Y2IG6r/KE+KiD8dkN6ul/Ri29N4V7MVLZ48zbikiyX9nlrcd4W+flt92G9tHNnPlvR0RDwTEQck3SlpVQt9DLyIeEDS3iMWr5K0obq/QRO/LH3XobeBEBGjEfFodX+/pNemGW913xX66os2wr5E0k8nPd6lwZrvPST90PYjtte23cwUFkXEqDTxyyNpYcv9HGnaabz76Yhpxgdm33Uz/XldbYR9qu/HGqTxvxUR8auSLpB0ZXW6ipmZ0TTe/TLFNOMDodvpz+tqI+y7JC2d9PhUSbtb6GNKEbG7uh2TdI8GbyrqPa/NoFvdjrXcz/8bpGm8p5pmXAOw79qc/ryNsD8s6Qzb77I9V9Klku5roY83sD1UvXEi20OSPqHBm4r6PklrqvtrJN3bYi+vMyjTeHeaZlwt77vWpz+PiL7/SLpQE+/I/0TSn7XRQ4e+3i3psernibZ7k3SHJk7rDmrijOhySSdL2iRpR3W7YIB6u03S45K2aiJYi1vq7dc08afhVklbqp8L2953hb76st+4XBZIgivogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wNGNvRIqiy+UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = x_test[0].reshape((28,28))\n",
    "test_image = (test_image * 255).astype('uint8')\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "# 传统的定义方法\n",
    "def autoencode(x):\n",
    "    #l1 = tf.nn.tanh(fc_layer(x, 28*28, 50))\n",
    "    #l2 = tf.nn.tanh(fc_layer(l1, 50, 50))\n",
    "    #l3 = fc_layer(l2, 50, 2)\n",
    "    #l4 = tf.nn.tanh(fc_layer(l3, 2, 50))\n",
    "    #l5 = tf.nn.tanh(fc_layer(l4, 50, 50))\n",
    "    l1 = Dense(128,activation = tf.nn.relu)(x)\n",
    "    l2 = Dense(128,activation = tf.nn.relu)(l1)\n",
    "    l3 = Dense(32)(l2)\n",
    "    l4 = Dense(128,activation = tf.nn.relu)(l3)\n",
    "    l5 = Dense(128,activation = tf.nn.relu)(l4)\n",
    "    out = Dense(input_size,activation = 'sigmoid')(l5)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.squared_difference(x, out))\n",
    "    return loss, out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "WARNING:tensorflow:From /home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "this is the  0  epoch\n",
      "this is the  1  epoch\n",
      "this is the  2  epoch\n",
      "this is the  3  epoch\n",
      "this is the  4  epoch\n",
      "this is the  5  epoch\n",
      "this is the  6  epoch\n",
      "this is the  7  epoch\n",
      "this is the  8  epoch\n",
      "this is the  9  epoch\n",
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# difine two placeholder。This is the old fashion tensorflow method\n",
    "# 训练自编码，传统方式在使用一天之后终于奏效了\n",
    "x_pl = tf.placeholder(tf.float32,shape = [None,input_size],name = 'x_pl')\n",
    "print(x_pl.shape)\n",
    "batchsize = 20\n",
    "range_val = int(60000/batchsize)\n",
    "loss,output = autoencode(x_pl)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        if(epoch % 1 == 0):\n",
    "            print('this is the ',epoch,' epoch')\n",
    "        for i in range(range_val):\n",
    "            batch_index = i\n",
    "            train_i = x_train[batchsize * batch_index:batchsize * (batch_index + 1),:]\n",
    "            feed = {x_pl:train_i} \n",
    "            my_loss ,_ = sess.run([loss,train_op],feed_dict =feed)\n",
    "    # save the model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess,os.path.join(LOG_DIR,'autoencoder2.ckpt'))\n",
    "    # check the output of the result\n",
    "    test_img = x_test[0].reshape((1,784))\n",
    "    networkoutput = sess.run(output,feed_dict = {x_pl:test_img})\n",
    "    print(networkoutput.shape)\n",
    "    output_img = networkoutput.reshape((28,28))\n",
    "    output_img = (output_img * 255).astype('uint8')\n",
    "    plt.imshow(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 102       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 784)               39984     \n",
      "=================================================================\n",
      "Total params: 84,586\n",
      "Trainable params: 84,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Dense(50,input_shape = (input_size,),activation = 'tanh'))\n",
    "model.add(Dense(50,activation = 'tanh'))\n",
    "model.add(Dense(2))\n",
    "model.add(Dense(50,activation = 'tanh'))\n",
    "model.add(Dense(50,activation = 'tanh'))\n",
    "model.add(Dense(input_size))\n",
    "model.summary()\n",
    "def cusloss(ytrue,ypred):\n",
    "    loss = tf.reduce_sum(tf.squared_difference(ypred,ytrue))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 1375.7302\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 1193.4624\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 1131.2236\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 1100.8460\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 1083.6932\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 1071.2350\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 1059.0790\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 1044.7049\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 1037.5867\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 1030.4747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa4541ae0b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = cusloss,\n",
    "              optimizer = 'adam')\n",
    "model.fit(x_train,x_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x324 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_autoencoder_outputs(model, 5, (28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "x_train = np.reshape(x_train,[60000,28,28,1])\n",
    "x_test = np.reshape(x_test,[10000,28,28,1])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传统的定义方法\n",
    "def digitNet(x,label):\n",
    "    conv1 = Conv2D(32,(5,5),activation = 'relu')(x)\n",
    "    MP1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    Dp1 =Dropout(rate = 0.2)(MP1)\n",
    "    Flat = Flatten()(Dp1)\n",
    "    fc1 = Dense(128,activation = 'relu')(Flat)\n",
    "    out = Dense(10,activation = 'softmax')(fc1)\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=out, labels=label)\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n",
      "(?,)\n",
      "this is the  0  epoch\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_4/Conv2D (defined at <ipython-input-23-f8b431c15015>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-23-f8b431c15015>:10) ]]\n\nCaused by op 'conv2d_4/Conv2D', defined at:\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-e6b6a084a8d6>\", line 11, in <module>\n    loss,output = digitNet(x_pl,label_pl)\n  File \"<ipython-input-23-f8b431c15015>\", line 3, in digitNet\n    conv1 = Conv2D(32,(5,5),activation = 'relu')(x)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_4/Conv2D (defined at <ipython-input-23-f8b431c15015>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-23-f8b431c15015>:10) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_4/Conv2D}}]]\n\t [[{{node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e6b6a084a8d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mlabel_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx_pl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_pl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel_i\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mmy_loss\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_4/Conv2D (defined at <ipython-input-23-f8b431c15015>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-23-f8b431c15015>:10) ]]\n\nCaused by op 'conv2d_4/Conv2D', defined at:\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-24-e6b6a084a8d6>\", line 11, in <module>\n    loss,output = digitNet(x_pl,label_pl)\n  File \"<ipython-input-23-f8b431c15015>\", line 3, in digitNet\n    conv1 = Conv2D(32,(5,5),activation = 'relu')(x)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_4/Conv2D (defined at <ipython-input-23-f8b431c15015>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-23-f8b431c15015>:10) ]]\n"
     ]
    }
   ],
   "source": [
    "# difine two placeholder。This is the old fashion tensorflow method\n",
    "# 训练数字识别器，loss function选择了和POINTNER++一样的方式去构建 \n",
    "x_pl = tf.placeholder(tf.float32,shape = [None,28,28,1],name = 'x_pl')\n",
    "label_pl = tf.placeholder(tf.int32,shape = [None],name = 'label_pl')\n",
    "print(x_pl.shape)\n",
    "print(label_pl.shape)\n",
    "\n",
    "batchsize = 20\n",
    "range_val = int(60000/batchsize)\n",
    "\n",
    "loss,output = digitNet(x_pl,label_pl)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        if(epoch % 1 == 0):\n",
    "            print('this is the ',epoch,' epoch')\n",
    "        for i in range(range_val):\n",
    "            batch_index = i\n",
    "            train_i = x_train[batchsize * batch_index:batchsize * (batch_index + 1),:]\n",
    "            label_i = y_train[batchsize * batch_index:batchsize * (batch_index + 1)]\n",
    "            feed = {x_pl:train_i,label_pl:label_i} \n",
    "            my_loss ,_ = sess.run([loss,train_op],feed_dict =feed)\n",
    "            \n",
    "    # save the model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess,os.path.join(LOG_DIR,'digitNet.ckpt'))\n",
    "    # check the output of the result\n",
    "    test_img = x_test[0].reshape(1,28,28,1)\n",
    "    networkoutput = sess.run(output,feed_dict = {x_pl:test_img})\n",
    "    prediction = np.argmax(networkoutput)\n",
    "    print('networkoutput',networkoutput.shape)\n",
    "    print('prediction = ',prediction,prediction.shape)\n",
    "    print('label = ',y_test[0])\n",
    "    #output_img = networkoutput.reshape((28,28))\n",
    "    #output_img = (output_img * 255).astype('uint8')\n",
    "    #plt.imshow(output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_img (1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#print('networkoutput = ',networkoutput)\n",
    "test_img = x_test[0].reshape(1,28,28,1)\n",
    "print('test_img',test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上面图过后成功完成训练了，接下来就是保存模型并提取模型，然后用自编码模型完成老师的任务了\n",
    "# restore the model\n",
    "MODEL_PATH = os.path.join(LOG_DIR,'digitNet.ckpt')\n",
    "# 要先把网络结构重新引进回来之后才能使用saver\n",
    "x_pl = tf.placeholder(tf.float32,shape = [None,28,28,1],name = 'x_pl')\n",
    "label_pl = tf.placeholder(tf.int32,shape = [None],name = 'label_pl')\n",
    "_,output = digitNet(x_pl,label_pl)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 这个方法需要每一个tensor的名字来使用，还不如重新声明一次网络来的实在\n",
    "    # saver = tf.train.import_meta_graph(LOG_DIR + '/digitNet.ckpt.meta')\n",
    "    graph = tf.get_default_graph()    \n",
    "    saver.restore(sess, MODEL_PATH)\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "    networkoutput = sess.run(output,feed_dict = {x_pl:test_img})\n",
    "    \n",
    "    prediction = np.argmax(networkoutput)\n",
    "    print('networkoutput',networkoutput.shape)\n",
    "    print('prediction = ',prediction,prediction.shape)\n",
    "    print('label = ',y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
