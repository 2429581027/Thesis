{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2JOnce deleted, variables cannot be recovered. Proceed (y/[n])? n\n",
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "%clear\n",
    "%reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working dirctory =  /home/chaotang/文档/Try\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "# this code is used to check whether my gradient calculation can be used\n",
    "import os\n",
    "import sys\n",
    "BASE_DIR = os.getcwd()\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print('current working dirctory = ',BASE_DIR)\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current log dirctory =  /home/chaotang/文档/Try/log\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = BASE_DIR + '/log'\n",
    "# 设定了一个log 的路径，方便如何存入和读取模型\n",
    "if not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\n",
    "print('current log dirctory = ',LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit recognition Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#x_train = np.round(x_train/255)\n",
    "#x_test = np.round(x_test/255)\n",
    "x_train = np.round(x_train)/255\n",
    "x_test = np.round(x_test)/255\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = np.reshape(x_train,[60000,28,28,1])\n",
    "x_test = np.reshape(x_test,[10000,28,28,1])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传统的定义方法\n",
    "def digitNet(x,label):\n",
    "    conv1 = Conv2D(32,(5,5),activation = 'relu',name = 'conv1')(x)\n",
    "    #print('conv1',conv1.shape) #(20, 26, 26, 32)\n",
    "    MP1 = MaxPooling2D(pool_size=(2, 2),name = 'MP1')(conv1)\n",
    "    #print('MP1',MP1.shape) # (20, 13, 13, 32)\n",
    "    conv2 = Conv2D(32,(3,3),activation = 'relu',name = 'conv2')(MP1)\n",
    "    #print('conv2',conv2.shape) # (20, 11, 11, 32)\n",
    "    MP2 = MaxPooling2D(pool_size=(2, 2),name = 'MP2')(conv2)\n",
    "    #print('MP2',MP2.shape) # (20, 5, 5, 32)\n",
    "    # Dp1 =Dropout(rate = 0.2,name = 'Dp1')(MP1)\n",
    "    # go down one more. Add one more conv and one more mp\n",
    "    # leave the dp1\n",
    "    Flat = Flatten()(MP2)\n",
    "    #print('Flat',Flat.shape) # (20, 800)\n",
    "    fc1 = Dense(128,activation = 'relu',name = 'fc1')(Flat)\n",
    "    #out = Dense(10,activation = 'softmax',name = 'out')(fc1)\n",
    "    #print('fc1',fc1.shape) # (20, 128)\n",
    "    #Dp1 =Dropout(rate = 0.3,name = 'Dp1')(fc1)\n",
    "    out = Dense(10,name = 'out')(fc1)\n",
    "    \n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=out, labels=label)\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1)\n",
      "(32,)\n",
      "WARNING:tensorflow:From /home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "conv1/kernel:0\n",
      "conv1/bias:0\n",
      "conv2/kernel:0\n",
      "conv2/bias:0\n",
      "fc1/kernel:0\n",
      "fc1/bias:0\n",
      "out/kernel:0\n",
      "out/bias:0\n",
      "this is the  0  epoch\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv1/Conv2D (defined at <ipython-input-5-51e8495a51b9>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-5-51e8495a51b9>:22) ]]\n\nCaused by op 'conv1/Conv2D', defined at:\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 708, in __init__\n    self.run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-076b211d7d38>\", line 12, in <module>\n    loss,output = digitNet(x_pl,label_pl)\n  File \"<ipython-input-5-51e8495a51b9>\", line 3, in digitNet\n    conv1 = Conv2D(32,(5,5),activation = 'relu',name = 'conv1')(x)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv1/Conv2D (defined at <ipython-input-5-51e8495a51b9>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-5-51e8495a51b9>:22) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv1/Conv2D}}]]\n\t [[{{node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-076b211d7d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mlabel_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx_pl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_pl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel_i\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mmy_loss\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv1/Conv2D (defined at <ipython-input-5-51e8495a51b9>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-5-51e8495a51b9>:22) ]]\n\nCaused by op 'conv1/Conv2D', defined at:\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/chaotang/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 708, in __init__\n    self.run()\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-076b211d7d38>\", line 12, in <module>\n    loss,output = digitNet(x_pl,label_pl)\n  File \"<ipython-input-5-51e8495a51b9>\", line 3, in digitNet\n    conv1 = Conv2D(32,(5,5),activation = 'relu',name = 'conv1')(x)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 194, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 966, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 591, in __call__\n    return self.call(inp, filter)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 208, in __call__\n    name=self.name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1026, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/chaotang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nUnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv1/Conv2D (defined at <ipython-input-5-51e8495a51b9>:3) ]]\n\t [[node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-5-51e8495a51b9>:22) ]]\n"
     ]
    }
   ],
   "source": [
    "# difine two placeholder。This is the old fashion tensorflow method\n",
    "# 训练数字识别器，loss function选择了和POINTNER++一样的方式去构建 \n",
    "tf.reset_default_graph()\n",
    "batchsize = 32\n",
    "range_val = int(60000/batchsize)\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32,shape = [batchsize,28,28,1],name = 'x_pl')\n",
    "label_pl = tf.placeholder(tf.int32,shape = [batchsize],name = 'label_pl')\n",
    "print(x_pl.shape)\n",
    "print(label_pl.shape)\n",
    "\n",
    "loss,output = digitNet(x_pl,label_pl)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "# add summary writers\n",
    "saver = tf.train.Saver()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "for var in tf.trainable_variables():\n",
    "    print(var.name)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    train_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "    for epoch in range(10):\n",
    "        if(epoch % 1 == 0):\n",
    "            print('this is the ',epoch,' epoch')\n",
    "        for i in range(range_val):\n",
    "            batch_index = i\n",
    "            train_i = x_train[batchsize * batch_index:batchsize * (batch_index + 1),:]\n",
    "            label_i = y_train[batchsize * batch_index:batchsize * (batch_index + 1)]\n",
    "            feed = {x_pl:train_i,label_pl:label_i} \n",
    "            my_loss ,_ = sess.run([loss,train_op],feed_dict =feed)\n",
    "            \n",
    "    # save the model\n",
    "    save_path = saver.save(sess,os.path.join(LOG_DIR,'MydigitNet.ckpt'))\n",
    "    # check the output of the result\n",
    "    test_img = np.zeros((20,28,28,1))\n",
    "    test_img[0] = x_test[0].reshape(1,28,28,1)\n",
    "    networkoutput = sess.run(output,feed_dict = {x_pl:test_img})\n",
    "    prediction = np.argmax(networkoutput)\n",
    "    print('networkoutput',networkoutput.shape)\n",
    "    print('prediction = ',prediction)\n",
    "    print('label = ',y_test[0])\n",
    "    #output_img = networkoutput.reshape((28,28))\n",
    "    #output_img = (output_img * 255).astype('uint8')\n",
    "    #plt.imshow(output_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('networkoutput = ',networkoutput)\n",
    "test_index = 3\n",
    "test_img = np.zeros((20,28,28,1))\n",
    "\n",
    "test_img[0] = x_test[test_index].reshape(1,28,28,1)\n",
    "test_label = y_test[test_index].astype('int32')\n",
    "print('test_label',test_label)\n",
    "# add Noise\n",
    "\n",
    "Noise_img = np.zeros((test_img.shape))\n",
    "Noise_img = test_img + 0.0* np.random.normal(size = (1,28,28,1))\n",
    "Noise_img = np.clip(Noise_img,0,1)\n",
    "\n",
    "print('test_img',test_img.shape)\n",
    "print('Noise_img',Noise_img.shape)\n",
    "plt.figure()\n",
    "plt.imshow(test_img[0].reshape((28,28)))\n",
    "plt.figure()\n",
    "plt.imshow(Noise_img[0].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varify different position of pixel change would have different effect on score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Flat image\n",
    "Flat_img = np.zeros((1,28,28,1))\n",
    "# Flat_img\n",
    "# Test the sensitivity of the pixel to the current score\n",
    "score_mat = np.zeros((11,28,28,1))\n",
    "\n",
    "for i in range(11):\n",
    "    score_mat[i,5,4,:] = 0.1 * i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 证明不同位置变化对分数有影响 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the model\n",
    "# also remember to reset_everything to defaut!!!\n",
    "tf.reset_default_graph()\n",
    "MODEL_PATH = os.path.join(LOG_DIR,'MydigitNet.ckpt')\n",
    "# Have to redifine Graph\n",
    "x_pl = tf.placeholder(tf.float32,shape = [None,28,28,1],name = 'x_pl')\n",
    "label_pl = tf.placeholder(tf.int32,shape = [None],name = 'label_pl')\n",
    "\n",
    "loss,output = digitNet(x_pl,label_pl)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess: \n",
    "    saver.restore(sess, MODEL_PATH)\n",
    "    print(\"Model restored.\")\n",
    "    #############################################################\n",
    "    ### Expect to see score to be all zero when Flat_img input###\n",
    "    #############################################################\n",
    "    Flat_feed = {x_pl:Flat_img}\n",
    "    FlatOut= sess.run(output,feed_dict =Flat_feed) # Flat input should output 0 score for all the class\n",
    "    Net_offset = FlatOut[0,...]\n",
    "    print('Net_offset = ',Net_offset)\n",
    "    #\n",
    "    # The output socre for an important location\n",
    "    feed = {x_pl:score_mat}\n",
    "    output1= sess.run(output,feed_dict =feed)\n",
    "    S = np.zeros((10,11))\n",
    "    for i in range(10):\n",
    "        S[i,:] = output1[:,i] - Net_offset[i]\n",
    "        plt.figure()\n",
    "        plt.plot(S[i])\n",
    "        plt.title(i)\n",
    "    #for i in range(11):\n",
    "    #    print('Output Score = ',output1[i,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Weight Mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mask_w = np.zeros((28,28,10)) # (28,28) across 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the model\n",
    "# also remember to reset_everything to defaut!!!\n",
    "tf.reset_default_graph()\n",
    "MODEL_PATH = os.path.join(LOG_DIR,'MydigitNet.ckpt')\n",
    "# Have to redifine Graph\n",
    "x_pl = tf.placeholder(tf.float32,shape = [None,28,28,1],name = 'x_pl')\n",
    "label_pl = tf.placeholder(tf.int32,shape = [None],name = 'label_pl')\n",
    "\n",
    "loss,output = digitNet(x_pl,label_pl)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess: \n",
    "    saver.restore(sess, MODEL_PATH)\n",
    "    print(\"Model restored.\")\n",
    "    #############################################################\n",
    "    ### Expect to see score to be all zero when Flat_img input###\n",
    "    #############################################################\n",
    "    Flat_feed = {x_pl:Flat_img} ## 但是这个offset 是全局的offset，真的能够适用吗?\n",
    "    FlatOut= sess.run(output,feed_dict =Flat_feed)\n",
    "    Net_offset = FlatOut[0,...]\n",
    "    print('Net_offset = ',Net_offset)\n",
    "    \n",
    "    # The output socre for all important location\n",
    "    count = 0\n",
    "    for row in range (28):\n",
    "        for col in range(28): \n",
    "            score_mat_i = np.zeros((11,28,28,1))\n",
    "            for i in range(11):\n",
    "                score_mat_i[i,row,col,:] = 0.1 * i\n",
    "                \n",
    "            feed = {x_pl:score_mat_i}\n",
    "            output_cpoint= sess.run(output,feed_dict =feed)\n",
    "            S = np.zeros((10,11))\n",
    "            for i in range(10):\n",
    "                S[i,:] = output_cpoint[:,i] - Net_offset[i]\n",
    "            # S[i,:] 是第i个class 的分数\n",
    "            S_min = np.amin(S,axis = 1)# shape = (10,)\n",
    "            S_max = np.amax(S,axis = 1)\n",
    "            # Two ways to define the sensitivity\n",
    "            # Sensitivity = S_max - S_min # 这个似乎不太合理，会把副方向的激发也当成正方向的激发\n",
    "            # Sensitivity = S_max - S[:,9]\n",
    "            Sensitivity =  S[:,9]\n",
    "            Mask_w[row,col,:] = Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    plt.figure()\n",
    "    imask = np.clip(Mask_w[...,i],0,1)\n",
    "    #imask = Mask_w[...,i]/np.amax(imask)\n",
    "    print(imask,np.amax(Mask_w[...,i]))\n",
    "    #plt.imshow(Mask_w[...,i]/np.amax(Mask_w[...,i]))\n",
    "    plt.imshow(imask)\n",
    "    plt.title(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoise Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上面图过后成功完成训练了，接下来就是保存模型并提取模型，然后用自编码模型完成老师的任务了\n",
    "# restore the model\n",
    "# also remember to reset_everything to defaut!!!\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 下文的NoiseOutput是上一个restore的输出结果，等价于Noiseoutput = digitNet(x_pl,label_pl)\n",
    "\n",
    "batchsize = 20\n",
    "MODEL_PATH = os.path.join(LOG_DIR,'MydigitNet.ckpt')\n",
    "###############################\n",
    "### Have to redifine Graph ####\n",
    "###############################\n",
    "# this is the new graph\n",
    "x_pl = tf.placeholder(tf.float32,shape = [batchsize,28,28,1],name = 'x_pl')\n",
    "# x_pl = Noise_img\n",
    "label_pl = tf.placeholder(tf.int32,shape = [batchsize],name = 'label_pl')\n",
    "\n",
    "deltax = tf.get_variable('deltax',dtype=tf.float32,shape = x_pl.shape,initializer = tf.zeros_initializer)\n",
    "# 必须要固定shape 才行，否则不允许如此设定变量\n",
    "\n",
    "New_x = tf.clip_by_value((x_pl + deltax),0,1)# this may need a clip operation\n",
    "#New_x = x_pl + deltax\n",
    "\n",
    "loss,output = digitNet(New_x,label_pl)\n",
    "pre_trained_list = []\n",
    "var_list = []\n",
    "for var in tf.trainable_variables():\n",
    "    print(var.name)\n",
    "    var_list.append(var)\n",
    "pre_trained_list = var_list[1:]\n",
    "print('###############################')\n",
    "for var in pre_trained_list:\n",
    "    print(var.name)\n",
    "print('This is the train-graph name')\n",
    "print('###############################')\n",
    "\n",
    "saver = tf.train.Saver(var_list=pre_trained_list)\n",
    "\n",
    "##################################\n",
    "####### Graph has been redefine###\n",
    "#################################\n",
    "# 训练条件配置\n",
    "train_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope = 'deltax:0')\n",
    "displacement_mat = np.zeros((500,28,28,1)) # store the displacement for every 100 iteration\n",
    "##############################################################\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([deltax]))\n",
    "    saver.restore(sess,MODEL_PATH)\n",
    "    print(\"Model restored.\")\n",
    "    #print('NoiseOutput',NoiseOutput[0])\n",
    "    print('TestLabel',test_label)\n",
    "    # define loss function (energy) \n",
    "    # E1 = deltaX^2\n",
    "    E1 = 0.5 * tf.reduce_sum(tf.square(deltax[0])) # this become a scalar/// the shape of deltax[0] = (28,28,1)\n",
    "    # E2 = Si ^ 2\n",
    "    E2 = -output[0,test_label]\n",
    "    \n",
    "    energy_total = E1 + E2\n",
    "    # optimizer define\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.005)\n",
    "    train_op = optimizer.minimize(energy_total,var_list = train_var)\n",
    "    feed = {x_pl:Noise_img[0].reshape((1,28,28,1))}\n",
    "    print('Noise_img',Noise_img.shape)\n",
    "    loss_mat = np.zeros((4000,))\n",
    "    for i in range(4000):\n",
    "        _,loss_in_loop = sess.run([train_op,energy_total],feed_dict = feed)\n",
    "        #print('energy_total',loss_in_loop)\n",
    "\n",
    "        loss_mat[i] = loss_in_loop\n",
    "        #if i%1 ==0:\n",
    "           # j = int(i/1)\n",
    "            #displacement_mat[j,...] = deltax[0].eval()  \n",
    "        \n",
    "    print('deltax= ',deltax[0].eval().shape)\n",
    "    displacement = deltax[0].eval()\n",
    "    #print('displacement = ',displacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_mat)\n",
    "print(np.amin(loss_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the model\n",
    "# also remember to reset_everything to defaut!!!\n",
    "tf.reset_default_graph()\n",
    "print('displacement_mat',displacement_mat.shape)\n",
    "\n",
    "MODEL_PATH = os.path.join(LOG_DIR,'MydigitNet.ckpt')\n",
    "# Have to redifine Graph\n",
    "x_pl = tf.placeholder(tf.float32,shape = [None,28,28,1],name = 'x_pl')\n",
    "label_pl = tf.placeholder(tf.int32,shape = [None],name = 'label_pl')\n",
    "\n",
    "loss,output = digitNet(x_pl,label_pl)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "print('test_label = ',test_label)\n",
    "Noise_mat = np.zeros((500,28,28,1))\n",
    "for i in range(500):\n",
    "    Noise_mat[i,...] = Noise_img[0,...]\n",
    "with tf.Session() as sess: \n",
    "    saver.restore(sess, MODEL_PATH)\n",
    "    print(\"Model restored.\")\n",
    "    # 设置输出小数点位数\n",
    "    np.set_printoptions(precision=10)\n",
    "    \n",
    "    feed1 = {x_pl:test_img}\n",
    "    output1 = sess.run(output,feed_dict =feed1)\n",
    "    \n",
    "    #Noise_img[:,16,9,:] +=1\n",
    "    \n",
    "    feed2 = {x_pl:Noise_img}\n",
    "    output2 = sess.run(output,feed_dict =feed2)\n",
    "    \n",
    "    feed3 = {x_pl:Noise_img + displacement.reshape(1,28,28,1)}\n",
    "    output3 = sess.run(output,feed_dict =feed3)\n",
    "    \n",
    "    feed4 = {x_pl:Noise_mat[0:20,...] + displacement_mat[0:20,...]}\n",
    "    output4 = sess.run(output,feed_dict =feed4)\n",
    "    \n",
    "    print('done with image output,calculating Error...')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置输出小数点位数\n",
    "np.set_printoptions(precision=5)\n",
    "plt.imshow(test_img[0].reshape((28,28)))\n",
    "print('Original score for testLabel= ',output1[0,test_label]) #test_label\n",
    "print('Original output = ',output1[0,:]) #test_label\n",
    "\n",
    "plt.figure()\n",
    "Old_noise = np.clip(Noise_img[0],0,1).reshape((28,28))\n",
    "plt.imshow(Old_noise)\n",
    "print('Noise score for testLabel= ',output2[0,test_label])\n",
    "print('Noise output = ',output2[0,:]) #test_label\n",
    "\n",
    "plt.figure()\n",
    "# Change \n",
    "Processed = np.clip(Noise_img[0] + displacement,0,1).reshape((28,28))\n",
    "plt.imshow(Processed)\n",
    "print('New score for testLabel= ',output3[0,test_label])\n",
    "print('New output= ',output3[0,:])\n",
    "\n",
    "print('different = ',  np.square(Processed-Old_noise).mean())\n",
    "print('Processed',Processed[5,4])\n",
    "#plt.figure()\n",
    "#plt.imshow(Mask_w[...,test_label]/np.amax(Mask_w[...,test_label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute the classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "########### Then compute the classification error################\n",
    "#################################################################\n",
    "feed5 = {x_pl:x_train}\n",
    "trainset_out = sess.run(output,feed_dict =feed5)\n",
    "#print('trainset_out',trainset_out.shape)\n",
    "train_pred = np.argmax(trainset_out,1)\n",
    "#print('train_pred',train_pred.shape)\n",
    "correct_train = 0\n",
    "for i in range(train_pred.shape[0]):\n",
    "    correct_train += int(train_pred[i]==y_train[i])\n",
    "print('The accuracy of classification in training set',correct_train/train_pred.shape[0])\n",
    "print('With correct case',correct_train)\n",
    "\n",
    "feed6 = {x_pl:x_test}\n",
    "testset_out = sess.run(output,feed_dict =feed6)\n",
    "test_pred = np.argmax(testset_out,1)\n",
    "correct_test = 0\n",
    "for i in range(test_pred.shape[0]):\n",
    "    correct_test += int(test_pred[i]==y_test[i])\n",
    "print('The accuracy of classification in test set',correct_test/test_pred.shape[0])\n",
    "print('With correct case',correct_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Mask to GradientDecent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the model\n",
    "# also remember to reset_everything to defaut!!!\n",
    "tf.reset_default_graph()\n",
    "batchsize = 20\n",
    "MODEL_PATH = os.path.join(LOG_DIR,'MydigitNet.ckpt')\n",
    "######################################################################\n",
    "### Have to redifine Graph ####\n",
    "###############################\n",
    "# this is the new graph\n",
    "x_pl = tf.placeholder(tf.float32,shape = [batchsize,28,28,1],name = 'x_pl')\n",
    "# x_pl = Noise_img\n",
    "label_pl = tf.placeholder(tf.int32,shape = [batchsize],name = 'label_pl')\n",
    "\n",
    "deltax = tf.get_variable('deltax',dtype=tf.float32,shape = x_pl.shape)\n",
    "# 必须要固定shape 才行，否则不允许如此设定变量\n",
    "\n",
    "New_x = tf.clip_by_value((x_pl + deltax),0,1)# this may need a clip operation\n",
    "#New_x = x_pl + deltax\n",
    "\n",
    "loss,output = digitNet(New_x,label_pl)\n",
    "pre_trained_list = []\n",
    "var_list = []\n",
    "for var in tf.trainable_variables():\n",
    "    #print(var.name)\n",
    "    var_list.append(var)\n",
    "pre_trained_list = var_list[1:]\n",
    "print('###############################')\n",
    "#for var in pre_trained_list:\n",
    "    #print(var.name)\n",
    "print('This is the train-graph name')\n",
    "print('###############################')\n",
    "\n",
    "saver = tf.train.Saver(var_list=pre_trained_list)\n",
    "##################################\n",
    "####### Graph has been redefine###\n",
    "##################################################################################\n",
    "# 训练条件配置\n",
    "train_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope = 'deltax:0')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([deltax]))\n",
    "    saver.restore(sess,MODEL_PATH)\n",
    "    print(\"Model restored.\")\n",
    "    \n",
    "    # define loss function (energy) \n",
    "    # E1 = deltaX^2\n",
    "    E1 =  0.5 * tf.reduce_sum(tf.square(deltax[0])) # this become a scalar/// the shape of deltax[0] = (28,28,1)\n",
    "    # E2 = Si \n",
    "    E2 = -output[0,test_label]\n",
    "    \n",
    "    energy_total = E1 + E2\n",
    "    # optimizer define\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.0002)\n",
    "    train_op = optimizer.minimize(energy_total,var_list = train_var)\n",
    "    feed = {x_pl:Noise_img}\n",
    "    print('Noise_img',Noise_img.shape)\n",
    "    for i in range(5000):\n",
    "        _,loss_in_loop = sess.run([train_op,energy_total],feed_dict = feed)\n",
    "        #print('energy_total',loss_in_loop)\n",
    "      \n",
    "        #if i%1 ==0:\n",
    "           # j = int(i/1)\n",
    "            #displacement_mat[j,...] = deltax[0].eval()  \n",
    "        \n",
    "    print('deltax= ',deltax[0].eval().shape)\n",
    "    displacement = deltax[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
